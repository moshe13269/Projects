# @package _group_

TrainTask:

  dataset_class:
    _target_: dataset.dataset.Dataset
    path2load:
      - /home/moshelaufer/PycharmProjects/datasets/tal_noise_shlomi/
#    /home/moshelaufer/PycharmProjects/datasets/tal_noise_1
    type_files: wav
    labels: True
    dataset_names: tal_noise_1

  input_shape:
    -
      -
      - 16384

  model:
    _target_: model.synth_autoencoder_model.SynthAutoEncoder

    inputs:
      - 16384
      - 1

    masking_transformer:
      _target_: layers.masking_transformer.MaskingTransformer
      percent2mask: 0.65

    conv_encoder:
      _target_: layers.conv_wav_encoder.ConvFeatureExtractionModel
      activation: gelu
      units: 512
      conv_layers:
        -
          - 512
          - 10 #6
          - 5 #3

        -
          - 512
          - 3
          - 2

        -
          - 512
          - 3
          - 2

        -
          - 512
          - 3
          - 2

        -
          - 512
          - 3
          - 2

        -
          - 512
          - 2
          - 2 #1

        -
          - 512
          - 2
          - 2 #1

      num_duplicate_layer:
        - 1
        - 1
        - 1
        - 1
        - 1
        - 1
        - 1

      dropout: 0.1
      conv_bias: True
#      mode: none


    conv_decoder:
      _target_: layers.conv_wav_decoder.ConvDecoderModel
      activation: gelu
      units: 1
      conv_layers:
        -
          - 512
          - 2
          - 2
          - 1

        -
          - 512
          - 2
          - 2
          - 1

        -
          - 512
          - 3
          - 2
          - 1

        -
          - 512
          - 3
          - 2
          - 1

        -
          - 512
          - 3
          - 2
          - 0

        -
          - 512
          - 3
          - 2
          - 0

        -
          - 512
          - 10
          - 5
          - 4

      num_duplicate_layer:
        - 1
        - 1
        - 1
        - 1
        - 1
        - 1
        - 1

      dropout: 0.1
      conv_bias: True

    top_k_transformer: 1

    transformer_encoder:
      _target_: layers.transformer_encoder.EncoderTransformer
      num_layers: 8
      d_model: 512
      num_attention_heads: 12
      dff: 768
      dropout_rate: 0.1
      dim_conv: 1
      activation: gelu

    transformer_decoder:
      _target_: layers.transformer_decoder.DecoderTransformer
      num_layers: 8
      d_model: 512
      num_attention_heads: 12
      dff: 768
      dropout_rate: 0.1
      dim_conv: 1
      activation: gelu

    params_predictor:
      _target_: layers.params_predictor.ParamsPredictor

    linear_classifier:
      _target_: layers.linear_classifier.LinearClassifier
      activation: softmax
      outputs_dimension_per_outputs:
        - 16
        - 4 #16
        - 9 #8
        - 4 #8
        - 17 #9
        - 17 #8
        - 4 #9
        - 17 #9
        - 17
  #      - 4
  #      - 4
  #      - 4
  #      - 6 #17
  #      - 6 #17
  #      - 6 #17
  #      - 6 #17

  loss:
#    - _target_: losses.l2_regression.L2LossReg
    - _target_: losses.SpectralConvergengeLoss.SpectralConvergengeLoss
    - _target_: losses.LogSTFTMagnitudeLoss.LogSTFTMagnitudeLoss
    - _target_: losses.cos_sim_loss.CosSimLoss
#    - _target_: losses.soft_dtw_loss.SoftDTWLoss
#      gamma: 1.
#    - _target_: losses.l2_loss.L2Loss

  loss_ce:
    _target_: losses.cross_entropy_loss.CELoss
    num_classes: 1
    index_y_true: 1

  callbacks:
    -
      _target_: tensorflow.keras.callbacks.ModelCheckpoint
      filepath: /home/moshelaufer/PycharmProjects/results/checkpoint/synth_autoencoder/
      save_weights_only: False
      save_best_only: True
      save_freq: 'epoch'
      initial_value_threshold: 1
      monitor: 'loss'
      verbose: 1

    -
      _target_: tensorflow.keras.callbacks.LearningRateScheduler
      schedule:
        _target_: tensorflow.keras.optimizers.schedules.ExponentialDecay
        initial_learning_rate: 5e-4
        decay_steps: 30 #25
        decay_rate: 2e-4
#    -
#      _target_: callbacks.callbacks.LearnRateSchedulerTriStage
#      initial_lr: 0.0000001
#      peak: 0.000008
#      end: 0.00000001
#      steps2warp_up: 0.03
#      steps2hold: 0.67
#      decay: 0.3
#      train_steps_per_epoch: 563 #1250 #625
#      epochs: 60

#    -
#      _target_: tensorflow.keras.callbacks.EarlyStopping
#      monitor: linear_classifier #params_predictor
#      min_delta: 0.001
#      patience: 15
#      mode: min
#      verbose: 1
#      restore_best_weights: True
#      start_from_epoch: 200

  optimizer:
    _target_: tensorflow.keras.optimizers.Adam
    learning_rate: 0.000001
    beta_1: 0.9
    beta_2: 0.99

  processor:
    _target_: processors.processor_synth_encoder.Processor
    std_mean_calc:
      _target_: dataset.calc_std_mean_dataset_wav.StdMeanCalc
      path2dataset: /home/moshelaufer/PycharmProjects/datasets/tal_noise_25000_base/
    num_classes:
      - 16
      - 4 #16
      - 9 #8
      - 4 #8
      - 17 #9
      - 17 #8
      - 4 #9
      - 17 #9
      - 17 #2
      #      - 4
      #      - 4
      #      - 4
      #      - 6 #17
      #      - 6 #17
      #      - 6 #17
    #      - 6 #17

#    path2sets: /home/moshelaufer/PycharmProjects/datasets/tal_noise_25000_labels/list_of_set_labels.pkl


  batch_size:
    train: 32
    test: 1
    valid: 32

  epochs: 2000
  path2save_model: /home/moshelaufer/PycharmProjects/results/models
  model_name: synth_autoencoder
  path2save_csv: /home/moshelaufer/PycharmProjects/results/csv/synth_autoencoder/
  num_outputs: 12

  steps_per_epoch: 1000
  validation_steps: 50

  results:
    _target_: results.results.Results
    path2save_results: /home/moshelaufer/PycharmProjects/results/results/results
    num_class: 100

