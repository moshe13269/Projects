# @package _group_

TrainTask:

  dataset_class:
    _target_: dataset.dataset.Dataset
    path2load:
      - /home/moshelaufer/PycharmProjects/datasets/noy_synth/
    type_files: wav
    labels: True
    dataset_names: tal_noise_1

  model:
    _target_: model.synth_autoencoder_model_2_stft.SynthAutoEncoder

    inputs1:
      - 33 #129
      - 40 #512

    inputs2:
      - 33 #129
      - 1

    inputs3:
      - 33 #129
      - 1

    transformer:
      _target_: layers.transformer_2.Transformer
      num_transformer_blocks: 6
      d_model: 512
      num_heads: 24
      d_ff: 4096
      dropout: 0.15
      activation: gelu
      input_shape_encoder:
        - 257
        - 129
        - 1
      input_shape_decoder:
        - 257
        - 129
        - 1

    linear_classifier:
      _target_: layers.linear_classifier_2.LinearClassifier
      activation: relu
      dropout: 0.25
      outputs_dimension_per_outputs:
        - 3
        - 12
        - 20
        - 31
        - 4
        - 5
        - 8
        - 5
        - 16

  to_metrics: False #True #

  metrics:
    _target_: metrics.accuracy.CustomAccuracy
    num_classes: 1
    index_y_true: 1

  loss:
#    - _target_: losses.spectral_magnitude_losses.Spectral_LogSTFTMagnitude_Loss
    - _target_: losses.l2_loss.L2Loss

  loss_ce:
    _target_: losses.cross_entropy_loss_2.CELoss
    num_classes: 1
    index_y_true: 1
    outputs_dimension_per_outputs:
        - 3
        - 12
        - 20
        - 31
        - 4
        - 5
        - 8
        - 5
        - 16
  num_ce_loss: 1

  callbacks:
    -
      _target_: tensorflow.keras.callbacks.ModelCheckpoint
      filepath: /home/moshelaufer/PycharmProjects/results/checkpoint/synth_autoencoder_noy/
      save_weights_only: False
      save_best_only: True
      save_freq: 'epoch'
      initial_value_threshold: 1
      monitor: 'loss'
      verbose: 1

    -
      _target_: tensorflow.keras.callbacks.LearningRateScheduler
      schedule:
        _target_: callbacks.WarmLRSchedule
        initial_learning_rate: 1e-6
        warmup_steps: 25
        hold_step: 250
        decay_step: 2500
        max_learn_rate: 3e-5
        min_learn_rate: 1e-7

#      _target_: tensorflow.keras.callbacks.LearningRateScheduler
#      schedule:
#        _target_: tensorflow.keras.optimizers.schedules.ExponentialDecay
#        initial_learning_rate: 5e-5
#        decay_steps: 4000
#        decay_rate: 2e-4


  optimizer:
    _target_: tensorflow.keras.optimizers.Adam
    learning_rate: 0.000001
    beta_1: 0.9
    beta_2: 0.99

  processor:
    _target_: processors.processor_synth_encoder_mask_2_stft.Processor #processors.processor_synth_encoder.Processor #
    std_mean_calc:
      _target_: dataset.calc_std_mean_dataset_wav.StdMeanCalc
      path2dataset: /home/moshelaufer/PycharmProjects/datasets/tal_noise/
      stft: True
    mask:
      - 33 #129
      - 1
    num_classes:
      - 3
      - 12
      - 20
      - 31
      - 4
      - 5
      - 8
      - 5
      - 16

  batch_size:
    train: 128
    test: 1
    valid: 128

  epochs: 4000
  path2save_model: /home/moshelaufer/PycharmProjects/results/models/
  model_name: synth_autoencoder_2_stft_noy
  path2save_csv: /home/moshelaufer/PycharmProjects/results/csv/synth_autoencoder_2_stft/
  num_outputs: 2 #10 #1
  path2save_plot_model: /home/moshelaufer/PycharmProjects/results/plot/model_plot_tal_noise.png

  steps_per_epoch: 1000
  validation_steps: 250

  results:
    _target_: results.results.Results
    path2save_results: /home/moshelaufer/PycharmProjects/results/results/results
    num_class: 100

