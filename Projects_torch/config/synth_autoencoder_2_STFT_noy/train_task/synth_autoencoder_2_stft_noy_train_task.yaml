# @package _group_

TrainTask:

  dataset_class:
    _target_: dataset.dataset.Dataset
    path2load:
      - /home/moshelaufer/PycharmProjects/datasets/noy_synth/
    type_files: wav
    labels: True
    dataset_names: tal_noise_1

  saved_model: #/home/moshelaufer/PycharmProjects/results/checkpoint/synth_autoencoder_noy/

  model:
    _target_: Projects_torch.model.synth_tranformerE_model.SynthAutoEncoder

    # transformer:
    num_layers: 12
    d_model: 512
    nhead: 16

    conv_encoder:
      _target_: Projects_torch.layers.conv_wav_encoder.ConvFeatureExtractionModel
      activation: gelu
      units: 512
      conv_layers:
        -
          - 130     # (in_channels, dim, kernel, stride)
          - 512
          - 4
          - 2

        -
          - 512
          - 512
          - 3
          - 1

        -
          - 512
          - 512
          - 3
          - 1

        -
          - 512
          - 512
          - 2
          - 1

      num_duplicate_layer:
        - 1
        - 1
        - 1
        - 1

      dropout: 0.1
      conv_bias: True
      is_group_norm: True
      is_layer_norm: False

    linear_classifier:
      _target_: Projects_torch.layers.linear_classifier_2.LinearClassifier
      activation: relu
      dropout: 0.2
      outputs_dimension_per_outputs:
        - 3
        - 12
        - 20
        - 31
        - 4
        - 5
        - 8
        - 5
        - 16

  to_metrics: False #

  metrics:
    _target_: Projects_torch.metrics.accuracy_2.CustomAccuracy2
    outputs_dimension_per_outputs:
      - 3
      - 12
      - 20
      - 31
      - 4
      - 5
      - 8
      - 5
      - 16
#    num_classes: 1
#    index_y_true: 1

  loss:
#    - _target_: losses.spectral_magnitude_losses.Spectral_LogSTFTMagnitude_Loss
    - _target_: Projects_torch.losses.l2_loss.L2Loss

  loss_ce:
    _target_: Projects_torch.losses.cross_entropy_loss_2.CELoss
    num_classes: 1
    index_y_true: 1
    outputs_dimension_per_outputs:
        - 3
        - 12
        - 20
        - 31
        - 4
        - 5
        - 8
        - 5
        - 16
  num_ce_loss: 1

  loss_l2: False

  callbacks:
    -
      _target_: tensorflow.keras.callbacks.ModelCheckpoint
      filepath: /home/moshelaufer/PycharmProjects/results/checkpoint/synth_autoencoder_noy/8/
      save_best_only: True
      save_freq: 7500 #'epoch'
      initial_value_threshold: 5
      monitor: 'linear_classifier_loss'
      verbose: 1

#    -
#      _target_: tensorflow.keras.callbacks.LearningRateScheduler
#      schedule:
#        _target_: callbacks.WarmLRSchedule
#        initial_learning_rate: 0.5e-7
#        warmup_steps: 25
#        hold_step: 1
#        decay_step: 100
#        max_learn_rate: 1.5e-6
#        min_learn_rate: 3e-8
#    -
#      _target_: tensorflow.keras.callbacks.LearningRateScheduler
#      schedule:
#        _target_: tensorflow.keras.optimizers.schedules.ExponentialDecay
#        initial_learning_rate: 8.5e-5
#        decay_steps: 750
#        decay_rate: 1e-4

  to_schedule: True

  schedule:
    _target_: callbacks.WarmLRSchedule
    initial_learning_rate: 6e-6
    warmup_steps: 8
    hold_step: 1000 #1
    decay_step: 10
    max_learn_rate: 7.5e-5 #2.5e-5 #8e-6 #1.5e-6
    min_learn_rate: 1.5e-6 #9e-7

  optimizer:
    _target_: tensorflow.keras.optimizers.Adam
    learning_rate: 1e-4 #1.6e-6 #1.25e-6
#      _target_: tensorflow.keras.callbacks.LearningRateScheduler
#      schedule:
#      _target_: callbacks.WarmLRSchedule
#      initial_learning_rate: 0.5e-7
#      warmup_steps: 25
#      hold_step: 1
#      decay_step: 100
#      max_learn_rate: 1.5e-6
#      min_learn_rate: 3e-8

  processor:
    _target_: Projects_torch.processors.processor_synth_encoder_stft.DataLoaderSTFT
    masking: False
    norm_mean: 0.013329904
    norm_std: 0.041720923
#    std_mean_calc:
#      _target_: dataset.calc_std_mean_dataset_wav.StdMeanCalc
#      path2dataset: /home/moshelaufer/PycharmProjects/datasets/tal_noise/
#      stft: True
    mask:
      - 65 #33 #129
      - 1
    num_classes:
      - 3
      - 12
      - 20
      - 31
      - 4
      - 5
      - 8
      - 5
      - 16

  batch_size:
    train: 128 #48
    test: 1
    valid: 64 #48

  learning_rate: 3e-4 #0.5e-7

  epochs: 4000
  path2save_model: /home/moshela/work/moshe/pycharm/checkpoints/noy/checkpoint_4.pt #    /home/moshelaufer/PycharmProjects/results/models/
  model_name: synth_autoencoder_2_stft_noy
  path2save_csv: /home/moshelaufer/PycharmProjects/results/csv/synth_autoencoder_2_stft/
  num_outputs: 2 #10 #1
  path2save_plot_model: /home/moshelaufer/PycharmProjects/results/plot/model_plot_tal_noise.png

  steps_per_epoch: 1000 # 2500
  validation_steps: 150

  results:
    _target_: Projects_torch.results.results.Results
    path2save_results: /home/moshelaufer/PycharmProjects/results/results/results
    num_class: 100

