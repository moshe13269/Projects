train_task:
  TrainTask:
    dataset_class:
      _target_: dataset.dataset.Dataset
      path2load:
      - /home/moshelaufer/PycharmProjects/datasets/noy_synth/
      type_files: wav
      labels: true
      dataset_names: tal_noise_1
    saved_model: null
    model:
      _target_: Projects_tensorflow.model.synth_autoencoder_model_2_stft.SynthAutoEncoder
      inputs1:
      - 130
      - 129
      inputs2:
      - 65
      - 65
      conv_encoder:
        _target_: Projects_tensorflow.layers.conv_wav_encoder.ConvFeatureExtractionModel
        activation: gelu
        units: 512
        conv_layers:
        - - 512
          - 4
          - 2
        - - 512
          - 3
          - 1
        - - 512
          - 3
          - 1
        - - 512
          - 2
          - 1
        num_duplicate_layer:
        - 1
        - 1
        - 1
        - 1
        dropout: 0.1
        conv_bias: true
        is_group_norm: true
        is_layer_norm: false
      conv_decoder:
        _target_: Projects_tensorflow.layers.conv_wav_decoder.ConvDecoderModel
        activation: gelu
        units: 129
        conv_layers:
        - - 512
          - 2
          - 1
        - - 512
          - 3
          - 1
        - - 512
          - 3
          - 1
        - - 512
          - 4
          - 2
        num_duplicate_layer:
        - 1
        - 1
        - 1
        - 1
        dropout: 0.1
        conv_bias: true
        is_group_norm: true
        is_layer_norm: false
      transformer:
        _target_: Projects_tensorflow.layers.transformer.Transformer
        num_transformer_blocks: 12
        d_model: 512
        num_heads: 12
        d_ff: 3072
        dropout: 0.1
        activation: gelu
      linear_classifier:
        _target_: Projects_tensorflow.layers.linear_classifier_2.LinearClassifier
        activation: relu
        dropout: 0.2
        outputs_dimension_per_outputs:
        - 3
        - 12
        - 20
        - 31
        - 4
        - 5
        - 8
        - 5
        - 16
    to_metrics: false
    metrics:
      _target_: Projects_tensorflow.metrics.accuracy_2.CustomAccuracy2
      outputs_dimension_per_outputs:
      - 3
      - 12
      - 20
      - 31
      - 4
      - 5
      - 8
      - 5
      - 16
    loss:
    - _target_: Projects_tensorflow.losses.l2_loss.L2Loss
    loss_ce:
      _target_: Projects_tensorflow.losses.cross_entropy_loss_2.CELoss
      num_classes: 1
      index_y_true: 1
      outputs_dimension_per_outputs:
      - 3
      - 12
      - 20
      - 31
      - 4
      - 5
      - 8
      - 5
      - 16
    num_ce_loss: 1
    callbacks:
    - _target_: tensorflow.keras.callbacks.ModelCheckpoint
      filepath: /home/moshelaufer/PycharmProjects/results/checkpoint/synth_autoencoder_noy/9/
      save_best_only: true
      save_freq: 2000
      initial_value_threshold: 5
      monitor: linear_classifier_loss
      verbose: 1
    to_schedule: true
    schedule:
      _target_: Projects_tensorflow.callbacks.WarmLRSchedule
      initial_learning_rate: 6.0e-06
      warmup_steps: 8
      hold_step: 1000
      decay_step: 10
      max_learn_rate: 7.5e-05
      min_learn_rate: 1.5e-06
    optimizer:
      _target_: tensorflow.keras.optimizers.Adam
      learning_rate: 1.6e-06
    processor:
      _target_: Projects_tensorflow.processors.processor_synth_encoder_mask_2_stft.Processor
      norm_mean: 0.013329904
      norm_std: 0.041720923
      std_mean_calc:
        _target_: dataset.calc_std_mean_dataset_wav.StdMeanCalc
        path2dataset: /home/moshelaufer/PycharmProjects/datasets/tal_noise/
        stft: true
      mask:
      - 65
      - 1
      num_classes:
      - 3
      - 12
      - 20
      - 31
      - 4
      - 5
      - 8
      - 5
      - 16
    batch_size:
      train: 58
      test: 1
      valid: 58
    epochs: 4000
    path2save_model: /home/moshelaufer/PycharmProjects/results/models/
    model_name: synth_autoencoder_2_stft_noy
    path2save_csv: /home/moshelaufer/PycharmProjects/results/csv/synth_autoencoder_2_stft/
    num_outputs: 2
    path2save_plot_model: /home/moshelaufer/PycharmProjects/results/plot/model_plot_tal_noise.png
    steps_per_epoch: 1000
    validation_steps: 150
    results:
      _target_: Projects_tensorflow.results.results.Results
      path2save_results: /home/moshelaufer/PycharmProjects/results/results/results
      num_class: 100
optimizer:
  optimizer:
    _target_: optimizers.multi_optimizer.Optimizers
    indexes:
    - 1
    - 4
    - 5
    - 7
    ind_transformer_layer: 4
    optimizers:
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 9.88e-07
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 1.098e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 1.22e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 1.35e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 1.5e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 1.67e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 1.86e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 2.0667e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 2.296e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 2.55e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 2.83e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 3.15e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 3.5e-06
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 9.88e-07
          min_learn_rate: 3.0e-08
    - _target_: tensorflow.keras.optimizers.Adam
      learning_rate:
        _target_: tensorflow.keras.callbacks.LearningRateScheduler
        schedule:
          _target_: callbacks.WarmLRSchedule
          initial_learning_rate: 1.0e-07
          warmup_steps: 25
          hold_step: 1
          decay_step: 30
          max_learn_rate: 3.6e-06
          min_learn_rate: 3.0e-08
